{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from keras.models import Sequential,Model\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Activation, Input,RepeatVector,Embedding, Flatten, Concatenate,Dropout\n",
    "from keras.models import Model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from sklearn import metrics as mt\n",
    "from keras import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import average, concatenate,RepeatVector,Lambda,add,subtract\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "import random\n",
    "import os\n",
    "from keras import backend as K\n",
    "from keras.callbacks import (ModelCheckpoint, LearningRateScheduler,\n",
    "                             EarlyStopping, ReduceLROnPlateau,CSVLogger)\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "import pickle\n",
    "from keras.layers import Conv2D, MaxPooling2D,Conv1D,GlobalMaxPooling1D,MaxPooling1D,Reshape,Add\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D,AveragePooling1D\n",
    "from keras.regularizers import l2 \n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroe(y_true,y_pred):\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(\"ACC:\",accuracy_score(y_true, y_pred))\n",
    "\n",
    "#Prepare Data\n",
    "import numpy as np\n",
    "# with open('final_data_dude_rd2.npy', 'rb') as handle:\n",
    "data = np.load('final_data.npy').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45609\n",
      "Class 1: 22805\n",
      "[[1184, '3E37'], [1156, '2QD9'], [1144, '830C'], [1084, '2RGP'], [1074, '3KL6'], [1072, '1XL2'], [1066, '2I78'], [1064, '2OI0'], [1048, '3EL8'], [1016, '3L3M'], [984, '1BCD'], [968, '2GTK'], [964, '3EML'], [960, '3PBL'], [948, '1H00'], [922, '1YPE'], [906, '1E66'], [898, '2AYW'], [870, '3LN1'], [840, '2OF2'], [818, '2P2I'], [796, '1UDT'], [766, '1SJ0'], [746, '2P54'], [734, '2FSZ'], [676, '3LAN'], [660, '3FRJ'], [586, '3KBA'], [586, '3CQW'], [566, '3L5D'], [564, '3BKL'], [538, '2AM9'], [515, '3BQD'], [494, '2VT4'], [480, '2ZNP'], [462, '3NY8'], [462, '3NXO'], [398, '2CNK'], [390, '2OYU'], [370, '3MAX'], [364, '2HZI'], [342, '3CHP'], [340, '3NXU'], [340, '3F07'], [340, '3CCW'], [332, '3LQ8'], [332, '3KRJ'], [332, '3G0E'], [324, '1SQT'], [318, '2HV5'], [316, '3KGC'], [304, '3D4Q'], [296, '2ZEC'], [296, '2OJ9'], [278, '3C4F'], [276, '2ICA'], [270, '2I0E'], [266, '3HMM'], [262, '1MV9'], [260, '2AZR'], [244, '1S3B'], [242, '3EQH'], [240, '1R9O'], [234, '3D0E'], [232, '3CJO'], [228, '1W7X'], [222, '1J4H'], [222, '1D3G'], [218, '1SYN'], [214, '3LPB'], [214, '2OWB'], [208, '3G6Z'], [208, '2ZDT'], [206, '3BGS'], [206, '1Q4X'], [204, '3BIZ'], [204, '1LRU'], [202, '3M2W'], [202, '1VSO'], [200, '3NF7'], [200, '3HL5'], [200, '3BZ3'], [200, '2ETR'], [200, '1QW6'], [198, '1KVO'], [196, '1B9V'], [188, '2AA2'], [186, '2E1W'], [184, '3F9M'], [176, '1UYG'], [170, '1ZW5'], [158, '2OJG'], [154, '1C8K'], [126, '1LI4'], [114, '2B8T'], [108, '2V3F'], [100, '1NJS'], [96, '1L2S'], [94, '2NNQ'], [86, '2H7L'], [82, '3BWM'], [80, '3ODU']]\n",
      "(45609, 2, 9000) (45609, 512) (45609,)\n",
      "Class 0: 22804\n",
      "ratio: 1.0000438519557973\n"
     ]
    }
   ],
   "source": [
    "random.seed(23456)\n",
    "\n",
    "X, proteins, ic50 = data['X'], data['proteins'], data['score']\n",
    "print(len(X))\n",
    "k = sum(ic50)\n",
    "\n",
    "print ('Class 1:',k)\n",
    "print(\"Class 0:\",(len(ic50)-sum(ic50)) )\n",
    "\n",
    "td = {}\n",
    "\n",
    "pr = data['pr_names']\n",
    "\n",
    "for i in pr:\n",
    "\tif i not in td:\n",
    "\t\ttd[i] = 1\n",
    "\telse:\n",
    "\t\ttd[i] += 1\n",
    "li = [[td[i], i] for i in td]\n",
    "\n",
    "li = [i[1] for i in li]\n",
    "\n",
    "li.shuffle()\n",
    "\n",
    "#print (len(li))\n",
    "\n",
    "def get_fac():\n",
    "    \n",
    "    train = li[:72]\n",
    "    \n",
    "    fac = []\n",
    "    fac_t = []\n",
    "\n",
    "    pro_dic = {}\n",
    "\n",
    "    for i in range (len(pr)):\n",
    "        if pr[i] in train:\n",
    "            fac.append(i)\n",
    "        else:\n",
    "            if pr[i] in pro_dic:\n",
    "                pro_dic[pr[i]].append(i)\n",
    "            else:\n",
    "                pro_dic[pr[i]] = [i]\n",
    "            fac_t.append(i)\n",
    "    fac = np.array(fac)\n",
    "    fac_t = np.array(fac_t)\n",
    "    return fac, fac_t, train, pro_dic\n",
    "\n",
    "fac, fac_t, pro_dic = get_fac()\n",
    "\n",
    "proteins = np.array(proteins)\n",
    "X = np.array(X)\n",
    "ic50 = np.array(ic50)\n",
    "\n",
    "print (proteins.shape, X.shape, ic50.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 2)\n",
      "512\n",
      "(27187, 512) (18422, 512)\n"
     ]
    }
   ],
   "source": [
    "Proeins_shape=proteins.shape[1:]\n",
    "Drags_shape=X.shape[1]\n",
    "print(Proeins_shape)\n",
    "print(Drags_shape)\n",
    "\n",
    "def get_features():\n",
    "\n",
    "    train_X = X[fac]\n",
    "    valid_X = X[fac_t]\n",
    "\n",
    "    train_proteins = proteins[fac]\n",
    "    valid_proteins = proteins[fac_t]\n",
    "\n",
    "    train_y = ic50[fac]\n",
    "    valid_y = ic50[fac_t]\n",
    "    \n",
    "    return train_X, valid_X, train_proteins, valid_proteins, train_y, valid_y\n",
    "\n",
    "# In[11]:\n",
    "train_X, valid_X, train_proteins, valid_proteins, train_y, valid_y = get_features()\n",
    "\n",
    "print (train_X.shape, valid_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27187, 512) (27187,) (27187, 9000, 2)\n",
      "(54374, 512) (54374,) (54374, 9000, 2)\n"
     ]
    }
   ],
   "source": [
    "# add data by shuffling chains\n",
    "\n",
    "print (train_X.shape, train_y.shape, train_proteins.shape)\n",
    "\n",
    "\n",
    "def expand_train(train_X, train_y, train_proteins):\n",
    "    lis_X, lis_y, pro = [], [], []\n",
    "    for i in range (len(train_X)):\n",
    "\n",
    "        lis_X.append(train_X[i])\n",
    "        lis_y.append(train_y[i])\n",
    "        k = train_proteins[i].reshape((6, 1500, 2))\n",
    "        ik = random.shuffle(list(range(6)))\n",
    "        k = k[ik].reshape((9000, 2))\n",
    "        #a, b = k\n",
    "        #a = a[ik]\n",
    "        #b = b[ik]\n",
    "\n",
    "        #c = np.concatenate((a,b)).reshape(train_proteins.shape[1:])\n",
    "\n",
    "        #print (c.shape)\n",
    "        pro.append(k)\n",
    "        #if i%10000 ==0 and i !=0:\n",
    "        #    break\n",
    "            \n",
    "    train_X = np.concatenate((train_X, np.array(lis_X)))\n",
    "    train_y = np.concatenate((train_y, np.array(lis_y)))\n",
    "    train_proteins = np.concatenate((train_proteins, np.array(pro)))\n",
    "    \n",
    "    return train_X, train_y, train_proteins\n",
    "\n",
    "train_X, train_y, train_proteins = expand_train(train_X, train_y, train_proteins)\n",
    "    \n",
    "print (train_X.shape, train_y.shape, train_proteins.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callback_list_by_model(model_name):\n",
    " \n",
    "    checkpoint = ModelCheckpoint('model_zoo/'+model_name+'.h5', monitor='val_loss', verbose=1, \n",
    "                                 save_best_only=True, mode='min', save_weights_only = True)\n",
    "    reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, \n",
    "                                       verbose=1, mode='auto', epsilon=0.0001)\n",
    "    early = EarlyStopping(monitor=\"val_loss\", \n",
    "                          mode=\"min\", \n",
    "                          patience=7)\n",
    "    csv_logger = CSVLogger(filename='./training_log_'+model_name+'.csv',\n",
    "                       separator=',',\n",
    "                       append=True)\n",
    "    \n",
    "    callbacks_list = [checkpoint,reduceLROnPlat, early,csv_logger]\n",
    "    return callbacks_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,model_name,Epoch):\n",
    "    callbacks_list = get_callback_list_by_model(model_name)\n",
    "#     train_proteins_shuffle, train_X_shuffle, train_y_shuffle = shuffle(train_proteins, train_X, train_y,random_state=randomS)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mse',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(x=[train_proteins,train_X], # create a list of inputs for embeddings\n",
    "            y=train_y, epochs=Epoch, \n",
    "            batch_size=64, verbose=1,\n",
    "            validation_data = ([valid_proteins,valid_X],valid_y),\n",
    "            callbacks=callbacks_list         \n",
    "               )\n",
    "\n",
    "    re=np.round(np.squeeze(model.predict([valid_proteins,valid_X])))\n",
    "    scroe(re,list(valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_blocks(ft_number,k_size,input_tensor):\n",
    "    x = Conv1D(filters=ft_number, \n",
    "                     kernel_size=k_size, data_format='channels_last',\n",
    "                     padding='same',\n",
    "                     kernel_regularizer=l2(l2_lambda)\n",
    "              )(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    \n",
    "#     x = Conv1D(filters=ft_number, \n",
    "#                      kernel_size=k_size, \n",
    "#                      padding='same',\n",
    "#                      kernel_regularizer=l2(l2_lambda)\n",
    "#               )(x)\n",
    "#     x = Activation('relu')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "    \n",
    "    return x\n",
    "def op(inputs):\n",
    "    x, y = inputs\n",
    "    return K.pow((x - y), 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_branch(init_input,kernel_size):\n",
    "    x=conv_blocks(ft_number=32,k_size=kernel_size,input_tensor=init_input)\n",
    "    #x=MaxPooling1D(2,padding='same')(x)\n",
    "\n",
    "    x=conv_blocks(ft_number=64,k_size=kernel_size,input_tensor=x)\n",
    "    #x=MaxPooling1D(2,padding='same')(x)\n",
    "\n",
    "    x=conv_blocks(ft_number=128,k_size=kernel_size,input_tensor=x)\n",
    "    u = GlobalMaxPooling1D()(x)\n",
    "    u_broadcast=RepeatVector(x.shape[1])(u)\n",
    "\n",
    "    o=Lambda(op)([u_broadcast,x])  # K.pow((x - y), 2) \n",
    "    var = GlobalMaxPooling1D()(o)\n",
    "    X_vector = concatenate([u,var])\n",
    "    \n",
    "    #X_vector = Dense(64)(X_vector)\n",
    "    return X_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_lambda=0.05\n",
    "def create_multiBranch_Conv_model(Proeins_shape,Drags_shape):\n",
    "    \n",
    "    # left branch --> dimension reduction for Proeins_shape\n",
    "    \n",
    "    proeins_input_tensor = Input(shape=Proeins_shape, name='proeins_input_tensor')\n",
    "    #init_input = Reshape((Proeins_shape[1], Proeins_shape[0]),input_shape=Proeins_shape,name='init_input')(proeins_input_tensor)\n",
    "    init_input = proeins_input_tensor\n",
    "    #branch 0\n",
    "    w=conv_branch(init_input,10)\n",
    "    #branch 1\n",
    "    x=conv_branch(init_input,5)\n",
    "\n",
    "    #branch 2\n",
    "    y=conv_branch(init_input,15)\n",
    "    \n",
    "    #branch 3\n",
    "    z=conv_branch(init_input,20)\n",
    "    \n",
    "    protein_concat = concatenate([w,x,y,z], name='protein_concat_')\n",
    "    \n",
    "    protein_dense = Dense(128)(protein_concat)\n",
    "    protein_dense = BatchNormalization()(protein_dense)\n",
    "    protein_dense = Activation('relu')(protein_dense)\n",
    "    protein_dense = Dropout(0.5)(protein_dense)\n",
    "    \n",
    "    \n",
    "    # right branch --> dimension reduction for drug/ligand\n",
    "    drag_input_tensor = Input(shape=(Drags_shape,),name='drag_input_tensor')\n",
    "    d = Dense(128)(drag_input_tensor)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = Activation('relu')(d)\n",
    "    d = Dropout(0.5)(d)\n",
    "\n",
    "    \n",
    "#     # merge the branches together\n",
    "    final_branch = concatenate([protein_dense,d], name='protein_darg_concat_')\n",
    "    \n",
    "    final_dense = Dense(64)(final_branch)\n",
    "    final_dense = BatchNormalization()(final_dense)\n",
    "    final_dense = Activation('relu')(final_dense)\n",
    "    final_dense = Dropout(0.5)(final_dense)\n",
    "\n",
    "#     final_dense = Dense(32)(final_dense)\n",
    "#     final_dense = BatchNormalization()(final_dense)\n",
    "#     final_dense = Activation('relu')(final_dense)\n",
    "#     final_dense = Dropout(0.5)(final_dense)\n",
    "    \n",
    "    final_output = Dense(1, activation='sigmoid', name='final_output')(final_dense)\n",
    "    \n",
    "#     model = Model(inputs=proeins_input_tensor, outputs=protein_concat)\n",
    "    model = Model(inputs=[proeins_input_tensor,drag_input_tensor], outputs=final_output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/conda/lib/python3.6/site-packages/keras/callbacks.py:999: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54374 samples, validate on 18422 samples\n",
      "Epoch 1/40\n",
      "54374/54374 [==============================] - 308s 6ms/step - loss: 0.7848 - acc: 0.8490 - val_loss: 0.1113 - val_acc: 0.8615\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11130, saving model to model_zoo/multiBranch_Conv_model_copy.h5\n",
      "Epoch 2/40\n",
      "54374/54374 [==============================] - 298s 5ms/step - loss: 0.0668 - acc: 0.9214 - val_loss: 0.1011 - val_acc: 0.8736\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.11130 to 0.10114, saving model to model_zoo/multiBranch_Conv_model_copy.h5\n",
      "Epoch 3/40\n",
      "54374/54374 [==============================] - 298s 5ms/step - loss: 0.0518 - acc: 0.9404 - val_loss: 0.1002 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.10114 to 0.10020, saving model to model_zoo/multiBranch_Conv_model_copy.h5\n",
      "Epoch 4/40\n",
      "54374/54374 [==============================] - 298s 5ms/step - loss: 0.0404 - acc: 0.9520 - val_loss: 0.1194 - val_acc: 0.8533\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.10020\n",
      "Epoch 5/40\n",
      "54374/54374 [==============================] - 298s 5ms/step - loss: 0.0345 - acc: 0.9589 - val_loss: 0.1096 - val_acc: 0.8576\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.10020\n",
      "Epoch 6/40\n",
      "54374/54374 [==============================] - 298s 5ms/step - loss: 0.0275 - acc: 0.9659 - val_loss: 0.0856 - val_acc: 0.8915\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.10020 to 0.08559, saving model to model_zoo/multiBranch_Conv_model_copy.h5\n",
      "Epoch 7/40\n",
      "54374/54374 [==============================] - 297s 5ms/step - loss: 0.0244 - acc: 0.9697 - val_loss: 0.1224 - val_acc: 0.8485\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.08559\n",
      "Epoch 8/40\n",
      "54374/54374 [==============================] - 296s 5ms/step - loss: 0.0228 - acc: 0.9731 - val_loss: 0.0886 - val_acc: 0.8901\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.08559\n",
      "Epoch 9/40\n",
      "54374/54374 [==============================] - 296s 5ms/step - loss: 0.0267 - acc: 0.9768 - val_loss: 0.1038 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.08559\n",
      "Epoch 10/40\n",
      "54374/54374 [==============================] - 296s 5ms/step - loss: 0.0578 - acc: 0.9759 - val_loss: 0.1530 - val_acc: 0.8463\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.08559\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 11/40\n",
      "54374/54374 [==============================] - 296s 5ms/step - loss: 0.0253 - acc: 0.9803 - val_loss: 0.1961 - val_acc: 0.7818\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.08559\n",
      "Epoch 12/40\n",
      "54374/54374 [==============================] - 296s 5ms/step - loss: 0.0185 - acc: 0.9827 - val_loss: 0.1984 - val_acc: 0.7735\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.08559\n",
      "Epoch 13/40\n",
      "54374/54374 [==============================] - 296s 5ms/step - loss: 0.0167 - acc: 0.9844 - val_loss: 0.1200 - val_acc: 0.8602\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.08559\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.79      0.87     11300\n",
      "        1.0       0.75      0.97      0.84      7122\n",
      "\n",
      "avg / total       0.89      0.86      0.86     18422\n",
      "\n",
      "[[8968 2332]\n",
      " [ 243 6879]]\n",
      "ACC: 0.8602214743241776\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if 'model_zoo' not in os.listdir('.'):\n",
    "    os.mkdir('model_zoo')\n",
    "    \n",
    "multiBranch_Conv_model = create_multiBranch_Conv_model(Proeins_shape,Drags_shape,)\n",
    "#multiBranch_Conv_model.summary()\n",
    "evaluate_model(multiBranch_Conv_model,'multiBranch_Conv_model_copy',40)\n",
    "# SVG(model_to_dot(multiBranch_Conv_model,show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.963213864189632\n"
     ]
    }
   ],
   "source": [
    "multiBranch_Conv_model = create_multiBranch_Conv_model(Proeins_shape,Drags_shape,)\n",
    "multiBranch_Conv_model.load_weights('model_zoo/multiBranch_Conv_model_copy.h5')\n",
    "re1 =np.squeeze(multiBranch_Conv_model.predict([valid_proteins,valid_X]))\n",
    "print ('AUC', roc_auc_score(valid_y, re1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
